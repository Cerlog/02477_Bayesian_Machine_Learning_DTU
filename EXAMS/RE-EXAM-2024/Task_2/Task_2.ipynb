{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeea68b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# If you need to import from a local utils.py, uncomment and adjust the following lines:\n",
    "import sys\n",
    "import os\n",
    "import jax.numpy as jnp\n",
    "# Construct the full path to the folder\n",
    "folder_path = r'C:\\Users\\Petrb\\Desktop\\DTU\\3rdSemester\\02477_BAYESIAN_MACHINE_LEARNING'\n",
    "\n",
    "# Add the folder to the Python path\n",
    "sys.path.append(folder_path)\n",
    "\n",
    "# Now you can import the utils module\n",
    "from EXAMS.EXAM_2024.Task_2.utils import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli\n",
    "from kernel_gaussian_classes import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69beba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.array([-2.00, 0.00, 2.00])[:, None]\n",
    "y = jnp.array([-2.01, 1.41, 0.23])[:, None]\n",
    "\n",
    "\n",
    "kappa = jnp.sqrt(2)\n",
    "ell = 2.0\n",
    "sigma = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db42d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9999999  1.2130612  0.27067053]\n",
      " [1.2130612  1.9999999  1.2130612 ]\n",
      " [0.27067053 1.2130612  1.9999999 ]]\n"
     ]
    }
   ],
   "source": [
    "kernel = StationaryIsotropicKernel(kappa=kappa, lengthscale=ell, kernel_fun=squared_exponential)\n",
    "\n",
    "K_prior = kernel.contruct_kernel(x, x)\n",
    "\n",
    "print(K_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04cebaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = StationaryIsotropicKernel(kappa=kappa, lengthscale=ell, kernel_fun=squared_exponential)\n",
    "\n",
    "model = GaussianProcessRegression(x, y, kernel=kernel, sigma=sigma, kappa=kappa, lengthscale=ell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5138663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5283369 ]\n",
      " [ 0.8865025 ]\n",
      " [ 0.42873892]]\n",
      "[[ 0.20844185  0.02778709 -0.00998175]\n",
      " [ 0.02778697  0.19226015  0.02778709]\n",
      " [-0.00998175  0.02778709  0.20844197]]\n"
     ]
    }
   ],
   "source": [
    "mu, var = model.predict_f(x)\n",
    "print(mu)\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c892b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(X1, X2, length_scale=1.0, kappa=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Computes a “squared exponential style” kernel (here using an L₁ based form) plus a linear term.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X1 : np.ndarray, shape (n1, d)\n",
    "        First batch of points (n1 points in d dimensions).\n",
    "    X2 : np.ndarray, shape (n2, d)\n",
    "        Second batch of points (n2 points in d dimensions).\n",
    "    length_scale : float\n",
    "        Lengthscale parameter ell > 0 (default 1.0).\n",
    "    variance : float\n",
    "        Variance (amplitude) parameter σ² (default 1.0).  Currently not used in your return statement,\n",
    "        but you could multiply the whole kernel by this if desired.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    K : np.ndarray, shape (n1, n2)\n",
    "        Kernel matrix where\n",
    "          K[i,j] = 1 * (1 + (‖X1[i] − X2[j]‖₁ / (2 ℓ²)))⁻¹  +  X1[i] · X2[j]\n",
    "    \"\"\"\n",
    "    # ensure length_scale is positive and nonzero\n",
    "    l = np.abs(length_scale) + 1e-12\n",
    "    \n",
    "\n",
    "    \n",
    "    # 2) Compute pairwise differences via broadcasting:\n",
    "    #    diff[i,j,k] = X1[i,k] - X2[j,k]\n",
    "    #    shape of diff: (n1, n2, d)\n",
    "    diff = X1[:, None, :] - X2[None, :, :]\n",
    "    \n",
    "    # 3) Sum absolute differences over the last axis to get L1 distance:\n",
    "    #    sqdist[i,j] = sum_k |diff[i,j,k]|\n",
    "    #    shape of sqdist: (n1, n2)*\n",
    "    sqdist = np.linalg.norm((diff)**2, axis=2)\n",
    "    \n",
    "    \n",
    "    # 4) Compute the kernel:\n",
    "    #    A) “Squared‐exponential–style” term (but using L1 distance here):\n",
    "    #         (1 + sqdist / (2 ℓ²))⁻¹\n",
    "    #    B) Plus a linear term X1·X2ᵀ\n",
    "    #    Final shape: (n1, n2)\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        print(\"*\" * 50)\n",
    "        print(\"Debugging information:\")\n",
    "        \n",
    "        print(\"Length scale (l):\", l)\n",
    "        # 1) Print shapes for debugging\n",
    "        #   X1 shape: (n1, d)\n",
    "        print(\"X1 shape before:\", X1.shape)\n",
    "        #   After adding a new axis: (n1, 1, d)\n",
    "        print(\"X1[:, None, :] shape:\", X1[:, None, :].shape)\n",
    "        #   X2 shape: (n2, d)\n",
    "        print(\"X2 shape before:\", X2.shape)\n",
    "        #   After adding a new axis: (1, n2, d)\n",
    "        print(\"X2[None, :, :] shape:\", X2[None, :, :].shape)\n",
    "        #  diff shape: (n1, n2, d)\n",
    "        print(\"diff shape:\", diff.shape)\n",
    "        #  sqdist shape: (n1, n2)\n",
    "        print(\"sqdist shape:\", sqdist.shape)\n",
    "        #  K shape: (n1, n2)\n",
    "        print(\"K shape:\", np.exp(-0.5 * sqdist ) + 2 .shape)\n",
    "        # print K \n",
    "        print(\"K:\", np.exp(-0.5 * sqdist ) + 2 )\n",
    "        print(\"*\" * 50)\n",
    "        print(\"*\" * 50)\n",
    "    \n",
    "    return np.exp(-0.5 * sqdist ) + 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16aac54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior mean m(x*): 0.0 (assumed)\n",
      "prior variance C  :\n",
      " [[3.]]\n"
     ]
    }
   ],
   "source": [
    "xstar = np.array([[2.0]])\n",
    "\n",
    "C = rbf(xstar, xstar)\n",
    "\n",
    "print(\"prior mean m(x*): 0.0 (assumed)\")\n",
    "print(\"prior variance C  :\\n\", C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1d4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02477_Bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
