{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random numbers with JaX\n",
    "*Revision: 0.1 (23/4/25)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction and purpose\n",
    "\n",
    "In the Bayesian machine learning course, we often rely on random numbers for various computations. For example, if $p(\\mathbf{x})$ is some distribution of interest, and if can get access to a number of samples from this $p$, i.e. $\\mathbf{x}^{(i)} \\sim p(\\mathbf{x})$ for $i = 1, 2, \\dots, S$, then we can estimate most properties of the distribution $p(\\mathbf{x})$ using the samples. For example, we can use a *Monte Carlo*-estimator to estimate the expected value of the random variable with distribution $p(\\mathbf{x})$, i.e.\n",
    "\n",
    "$$\\mathbb{E}\\left[\\mathbf{x}\\right] \\approx \\hat{\\mathbf{x}} = \\frac{1}{S}\\sum_{i=1}^S \\mathbf{x}^{(i)},$$\n",
    "\n",
    "assuming the expected value exists. In almost every week, we have used random sampling for summarizing posterior and posterior predictive distributions, but random sampling also play a key role in several of the inference algorithms discussed in the course (MCMC, variational inference etc.). \n",
    "\n",
    "`JaX` has built-in support for sampling from many common distributions, e.g. Gaussians, Beta, Gamma etc., but random number generation in `JaX` is a bit different to other frameworks/packages because `JaX` requires us to specify an explicit `state` (the `key`) for the random number generator *every single time* we want `JaX` to generate a random number. It is beyond the scope of the course and this note to dive into the motivation why and to cover all technical and practical aspects of random number generator in `JaX`, but you can read more about it here https://docs.jax.dev/en/latest/random-numbers.html and here https://docs.jax.dev/en/latest/jep/263-prng.html#prng-design-jep if you are interested (but this is mean no means necessary to achieve all the learning objectives of the Bayesian Machine Learning course). Instead of aiming to cover every aspect of random number generation in `JaX`, we will in the following see an example of how to use random numbers in `JaX` and a couple of common mistakes. \n",
    "\n",
    "### Random numbers from a random number generator is not actual random\n",
    "\n",
    "First, we have to remind our selves that computers generally cannot generate *truly* random numbers. When we use `jax.random.normal`, `np.random.normal` or similar, we do not get a truly random samples from a Gaussian distribution. Instead we get the output from a *deterministic* algorithm designed to generate *pseudo random numbers* that *appear* and *behave* as if they were indeed truly random numbers from a Gaussian distribution.\n",
    "\n",
    "The algorithms behind `jax.random.normal` and `np.random.normal` depends on an initial `state`, i.e. the `seed` or `key`, and they are *100% deterministic* in the sense that they provide the same output when given the same initial `state`. Recall, in `JaX` the state of the random number generator is often called the `key` and hence, we will use the two terms (key & state) interchangably in this note.\n",
    "In `numpy`, we typically specify an initial `state` for the random number generator, and then `numpy` automatically updates the `state` internally to make sure we get different numbers every time we invoke the random number generator. \n",
    "\n",
    "For example, the cell below generates samples from a $\\mathcal{N}(0, 1)$-distribution, and if you keep the seed fixed, then running the cell below multiple times should generate the exact same output everytime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch of random numbers:\n",
      "1.764\n",
      "0.400\n",
      "0.979\n",
      "\n",
      "Second batch of random numbers:\n",
      "1.764\n",
      "0.400\n",
      "0.979\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# specify seed\n",
    "seed = 0\n",
    "\n",
    "# generate a batch of random numbers\n",
    "np.random.seed(seed)\n",
    "print('First batch of random numbers:')\n",
    "for i in range(3):\n",
    "    x = np.random.normal()\n",
    "    print(f'{x:4.3f}')\n",
    "\n",
    "# generate another batch of random numbers with same seed\n",
    "np.random.seed(seed)\n",
    "print('\\nSecond batch of random numbers:')\n",
    "for i in range(3):\n",
    "    x = np.random.normal()\n",
    "    print(f'{x:4.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to specify the initial random `state` is very convenient, because it is ensures reproducibility and makes debugging simpler.\n",
    "\n",
    "Let's now see a similar example in `JaX`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch of random numbers:\n",
      "1.623\n",
      "1.623\n",
      "1.623\n",
      "\n",
      "Second batch of random numbers:\n",
      "1.623\n",
      "1.623\n",
      "1.623\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "# specify seed\n",
    "seed = 0\n",
    "\n",
    "# generate a batch of random numbers\n",
    "key = jax.random.PRNGKey(seed)\n",
    "print('First batch of random numbers:')\n",
    "for i in range(3):\n",
    "    x = jax.random.normal(key)\n",
    "    print(f'{x:4.3f}')\n",
    "\n",
    "# generate another batch of random numbers with same seed\n",
    "key = jax.random.PRNGKey(seed)\n",
    "print('\\nSecond batch of random numbers:')\n",
    "for i in range(3):\n",
    "    x = jax.random.normal(key)\n",
    "    print(f'{x:4.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this is not what we want. The problem is that we did not update/change the `state/key` of the random number generator, and when we provide `JaX` with the same `key`, we get the same number.\n",
    "\n",
    "Instead, we should have done the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch of random numbers:\n",
      "-2.442\n",
      "-1.257\n",
      "-1.388\n",
      "\n",
      "Second batch of random numbers:\n",
      "-2.442\n",
      "-1.257\n",
      "-1.388\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "# specify seed\n",
    "seed = 0\n",
    "\n",
    "print('First batch of random numbers:')\n",
    "key = jax.random.PRNGKey(seed)\n",
    "for i in range(3):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    x = jax.random.normal(subkey)\n",
    "    print(f'{x:4.3f}')\n",
    "\n",
    "print('\\nSecond batch of random numbers:')\n",
    "key = jax.random.PRNGKey(seed)\n",
    "for i in range(3):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    x = jax.random.normal(subkey)\n",
    "    print(f'{x:4.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the desired behavior, where we get different numbers everytime we call `jax.random.normal`, but we can still reproduce a sequence of random numbers when desired. \n",
    "\n",
    "A random `state/key` in `JaX` is essentially just a tuple of two integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key [ 683029726 1624662641]\n"
     ]
    }
   ],
   "source": [
    "print('key', key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which controls the `state` of the random number generator. In this example above, we used the function `jax.random.split` to iteratively update the `state` of the random number generator. The function `split` essentially takes one `state/key` and splits it into two `states/keys`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key [ 683029726 1624662641]\n",
      "new_key1 [1113701576 1346130448]\n",
      "new_key2 [1539457558  118255239]\n"
     ]
    }
   ],
   "source": [
    "new_key1, new_key2 = jax.random.split(key)\n",
    "\n",
    "print('key', key)\n",
    "print('new_key1', new_key1)\n",
    "print('new_key2', new_key2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using the following pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(seed)\n",
    "for i in range(3):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    x = jax.random.normal(subkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensures that we never generate random numbers based on the same `state/key`, and hence, we get the desired behavior.\n",
    "\n",
    "Instead of splitting the `key` in every iteration, we could also have generated 3 `keys` from the beginning, i.e. creating a `list` containing 3 `keys`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch of random numbers:\n",
      "1.004\n",
      "-2.442\n",
      "1.296\n",
      "\n",
      "Second batch of random numbers:\n",
      "1.004\n",
      "-2.442\n",
      "1.296\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "# specify seed\n",
    "seed = 0\n",
    "\n",
    "print('First batch of random numbers:')\n",
    "key = jax.random.PRNGKey(seed)\n",
    "keys = jax.random.split(key, num=3)\n",
    "for i in range(3):\n",
    "    x = jax.random.normal(keys[i])\n",
    "    print(f'{x:4.3f}')\n",
    "\n",
    "print('\\nSecond batch of random numbers:')\n",
    "key = jax.random.PRNGKey(seed)\n",
    "keys = jax.random.split(key, num=3)\n",
    "for i in range(3):\n",
    "    x = jax.random.normal(keys[i])\n",
    "    print(f'{x:4.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the numbers here are different from the example above. The reason is that the sequence of generated keys are different in the two cases for technical reasons, but importantly, both implementations yield reproducible code. \n",
    "\n",
    "Updating/splitting the `key` in every iteration like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(seed)\n",
    "for i in range(3):\n",
    "    key, subkey = jax.random.split(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "has the advantage the new keys can be safely split into multiple keys in every iteration without risk of getting duplicate keys. For example, suppose now we are implementing an iterative algorithm, where we need to sample several different random variables in every iteration, then we can safely use the following pattern:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "(x,y,z) = (-2.442, 1.296, -0.622)\n",
      "\n",
      "Iteration 1\n",
      "(x,y,z) = (-1.257, -0.744, 0.340)\n",
      "\n",
      "Iteration 2\n",
      "(x,y,z) = (-1.388, -1.251, -0.343)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(seed)\n",
    "for i in range(3):\n",
    "    key, key_x, key_y, key_z = jax.random.split(key, num=4)\n",
    "    x = jax.random.normal(key_x)\n",
    "    y = jax.random.normal(key_y)\n",
    "    z = jax.random.normal(key_z)\n",
    "    print(f'Iteration {i}')\n",
    "    print(f'(x,y,z) = ({x:4.3f}, {y:4.3f}, {z:4.3f})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it is worth mentioning that we can also generate a sequence of $N$ random numbers using a single key as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 random numbers using a single key: [1.6359469  0.8408094  0.02212393]\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "\n",
    "key = random.PRNGKey(123)\n",
    "x = random.normal(key, shape=(N, ))\n",
    "print(f'{N} random numbers using a single key:', x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Three different implementations of a Monte Carlo estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude with a small example showing three ways to implemenent the random number generation for estimating the mean of $X^2 + Y^2$, where $X \\sim \\mathcal{N}(1, 2^2)$ and $Y \\sim \\mathcal{N}(0, 1)$ using $N = 1000$ samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo estimator for the mean of X^2 + Y^2: 6.138\n",
      "Monte Carlo estimator for the mean of X^2 + Y^2: 6.225\n",
      "Monte Carlo estimator for the mean of X^2 + Y^2: 5.878\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "N = 1000\n",
    "\n",
    "############################################################\n",
    "# implementation 1: update the key iteratively\n",
    "############################################################\n",
    "key = random.PRNGKey(1)\n",
    "values = []\n",
    "for i in range(N):\n",
    "    key, subkey_x, subkey_y = random.split(key, num=3)\n",
    "    x = 1 + 2*random.normal(subkey_x)\n",
    "    y = random.normal(subkey_y)\n",
    "    values.append(x**2 + y**2)\n",
    "print(f'Monte Carlo estimator for the mean of X^2 + Y^2: {jnp.mean(jnp.array(values)):4.3f}')\n",
    "\n",
    "############################################################\n",
    "# implementation 2: prepare list of keys beforehand\n",
    "############################################################\n",
    "key = random.PRNGKey(1)\n",
    "key_x, key_y = random.split(key, num=2)\n",
    "keys_x = random.split(key_x, num=N)\n",
    "keys_y = random.split(key_y, num=N)\n",
    "values = []\n",
    "for i in range(N):\n",
    "    x = 1 + 2*random.normal(keys_x[i])\n",
    "    y = random.normal(keys_y[i])\n",
    "    values.append(x**2 + y**2)\n",
    "print(f'Monte Carlo estimator for the mean of X^2 + Y^2: {jnp.mean(jnp.array(values)):4.3f}')\n",
    "\n",
    "\n",
    "############################################################\n",
    "# implementation 3: vectorized implementation\n",
    "############################################################\n",
    "key = random.PRNGKey(1)\n",
    "key_x, key_y = random.split(key, num=2)\n",
    "x = 1 + 2*random.normal(key_x, shape=(N, ))\n",
    "y = random.normal(key_y, shape=(N, ))\n",
    "print(f'Monte Carlo estimator for the mean of X^2 + Y^2: {jnp.mean(x**2 + y**2):4.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxpml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
