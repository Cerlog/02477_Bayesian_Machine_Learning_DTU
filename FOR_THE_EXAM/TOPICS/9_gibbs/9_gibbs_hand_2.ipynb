{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eeb9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, gamma, poisson\n",
    "import jax.random as random\n",
    "\n",
    "print(\"=== MCMC HAND CALCULATIONS IN PYTHON ===\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 1: BIMODAL DISTRIBUTION\n",
    "# =============================================================================\n",
    "print(\"PART 1: BIMODAL DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1.1 Theoretical Calculations\n",
    "print(\"\\n1.1 Theoretical Calculations\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Define the bimodal distribution\n",
    "def p_bimodal(x):\n",
    "    \"\"\"Bimodal distribution: 0.5 * N(x|-3, 4) + 0.5 * N(x|1, 2)\"\"\"\n",
    "    p1 = 0.5 * norm.pdf(x, loc=-3, scale=2)  # scale = sqrt(variance)\n",
    "    p2 = 0.5 * norm.pdf(x, loc=1, scale=np.sqrt(2))\n",
    "    return p1 + p2\n",
    "\n",
    "print(\"Distribution: p(x) = 0.5 × N(x|-3, 4) + 0.5 × N(x|1, 2)\")\n",
    "print(\"\\nTheoretical moments:\")\n",
    "print(\"E[X] = 0.5 × (-3) + 0.5 × 1 = -1\")\n",
    "print(\"E[X²] = 0.5 × (4 + 9) + 0.5 × (2 + 1) = 8\")\n",
    "print(\"Var[X] = E[X²] - (E[X])² = 8 - 1 = 7\")\n",
    "\n",
    "# 1.2 Metropolis Sampling - Hand Calculation\n",
    "print(\"\\n\\n1.2 Metropolis Sampling - Hand Calculation\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "x0 = 0\n",
    "tau = 0.5\n",
    "print(f\"Initial: x₀ = {x0}\")\n",
    "print(f\"Proposal variance: τ = {tau}\")\n",
    "\n",
    "# Iteration 1\n",
    "print(\"\\nIteration 1:\")\n",
    "epsilon1 = 0.8  # Example random number\n",
    "x_proposed = x0 + tau * epsilon1\n",
    "print(f\"1. Propose: x' = {x0} + {tau} × {epsilon1} = {x_proposed}\")\n",
    "\n",
    "p_x0 = p_bimodal(x0)\n",
    "p_xprop = p_bimodal(x_proposed)\n",
    "alpha = p_xprop / p_x0\n",
    "\n",
    "print(f\"2. Compute acceptance ratio:\")\n",
    "print(f\"   p(x₀) = p({x0}) = {p_x0:.4f}\")\n",
    "print(f\"   p(x') = p({x_proposed}) = {p_xprop:.4f}\")\n",
    "print(f\"   α = {p_xprop:.4f} / {p_x0:.4f} = {alpha:.3f}\")\n",
    "print(f\"3. Since α = {alpha:.3f} > 1, accept: x₁ = {x_proposed}\")\n",
    "\n",
    "x1 = x_proposed\n",
    "\n",
    "# Iteration 2\n",
    "print(\"\\nIteration 2:\")\n",
    "epsilon2 = -1.2\n",
    "x_proposed2 = x1 + tau * epsilon2\n",
    "print(f\"1. Propose: x' = {x1} + {tau} × {epsilon2} = {x_proposed2}\")\n",
    "\n",
    "p_x1 = p_bimodal(x1)\n",
    "p_xprop2 = p_bimodal(x_proposed2)\n",
    "alpha2 = p_xprop2 / p_x1\n",
    "\n",
    "print(f\"2. Compute acceptance ratio:\")\n",
    "print(f\"   p(x₁) = p({x1}) = {p_x1:.4f}\")\n",
    "print(f\"   p(x') = p({x_proposed2}) = {p_xprop2:.4f}\")\n",
    "print(f\"   α = {p_xprop2:.4f} / {p_x1:.4f} = {alpha2:.3f}\")\n",
    "\n",
    "u = 0.3  # Example uniform random number\n",
    "print(f\"3. Generate u ~ U(0,1) = {u}\")\n",
    "if u < alpha2:\n",
    "    x2 = x_proposed2\n",
    "    print(f\"   Since {u} < {alpha2:.3f}, accept: x₂ = {x_proposed2}\")\n",
    "else:\n",
    "    x2 = x1\n",
    "    print(f\"   Since {u} ≥ {alpha2:.3f}, reject: x₂ = {x1}\")\n",
    "\n",
    "# 1.3 Multiple Chains and R-hat Calculation\n",
    "print(\"\\n\\n1.3 Multiple Chains and R-hat Calculation\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Example chains\n",
    "chain1 = np.array([0.4, -0.2, -0.5, 0.8, 1.2])\n",
    "chain2 = np.array([-3.1, -2.8, -3.2, -2.9, -3.0])\n",
    "\n",
    "print(f\"Chain 1: {chain1}\")\n",
    "print(f\"Chain 2: {chain2}\")\n",
    "print(\"Notice: Chain 2 is stuck in the left mode!\")\n",
    "\n",
    "# Compute R-hat\n",
    "M = 2  # number of chains\n",
    "S = 5  # samples per chain\n",
    "\n",
    "# Chain means\n",
    "chain1_mean = np.mean(chain1)\n",
    "chain2_mean = np.mean(chain2)\n",
    "overall_mean = (chain1_mean + chain2_mean) / 2\n",
    "\n",
    "print(f\"\\nChain means:\")\n",
    "print(f\"θ̄₁ = {chain1_mean:.3f}\")\n",
    "print(f\"θ̄₂ = {chain2_mean:.3f}\")\n",
    "print(f\"θ̄ = {overall_mean:.3f}\")\n",
    "\n",
    "# Within-chain variances\n",
    "s1_sq = np.var(chain1, ddof=1)\n",
    "s2_sq = np.var(chain2, ddof=1)\n",
    "W = (s1_sq + s2_sq) / 2\n",
    "\n",
    "print(f\"\\nWithin-chain variances:\")\n",
    "print(f\"s₁² = {s1_sq:.3f}\")\n",
    "print(f\"s₂² = {s2_sq:.3f}\")\n",
    "print(f\"W = {W:.3f}\")\n",
    "\n",
    "# Between-chain variance\n",
    "B = S * np.var([chain1_mean, chain2_mean], ddof=1)\n",
    "\n",
    "print(f\"\\nBetween-chain variance:\")\n",
    "print(f\"B = {B:.3f}\")\n",
    "\n",
    "# R-hat\n",
    "R_sq = (S - 1) / S + B / (S * W)\n",
    "R_hat = np.sqrt(R_sq)\n",
    "\n",
    "print(f\"\\nR̂² = (S-1)/S + B/(S×W)\")\n",
    "print(f\"   = {(S-1)/S:.3f} + {B/(S*W):.3f}\")\n",
    "print(f\"   = {R_sq:.3f}\")\n",
    "print(f\"R̂ = {R_hat:.3f}\")\n",
    "print(f\"\\nThis high R̂ = {R_hat:.3f} indicates poor convergence!\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 2: CHANGE POINT DETECTION\n",
    "# =============================================================================\n",
    "print(\"\\n\\nPART 2: CHANGE POINT DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 2.1 Problem Setup\n",
    "print(\"\\n2.1 Problem Setup\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "data = np.array([3, 2, 1, 5, 6, 7])\n",
    "N = len(data)\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "print(f\"Data: x = {data}\")\n",
    "print(f\"N = {N} years\")\n",
    "print(f\"Hyperparameters: α = {alpha}, β = {beta}\")\n",
    "\n",
    "# 2.2 Gibbs Sampling - Hand Calculation\n",
    "print(\"\\n\\n2.2 Gibbs Sampling - Iteration 1\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Initial values\n",
    "c0 = 3\n",
    "lambda1_0 = 2.0\n",
    "lambda2_0 = 5.0\n",
    "\n",
    "print(f\"Initial values: c⁽⁰⁾ = {c0}, λ₁⁽⁰⁾ = {lambda1_0}, λ₂⁽⁰⁾ = {lambda2_0}\")\n",
    "\n",
    "# Step 1: Sample λ₁\n",
    "print(\"\\nStep 1: Sample λ₁ | x, c, λ₂\")\n",
    "sum_before = np.sum(data[:c0])\n",
    "alpha_1 = alpha + sum_before\n",
    "beta_1 = beta + c0\n",
    "\n",
    "print(f\"Sum of data before c = {c0}: {sum_before}\")\n",
    "print(f\"α' = {alpha} + {sum_before} = {alpha_1}\")\n",
    "print(f\"β' = {beta} + {c0} = {beta_1}\")\n",
    "print(f\"λ₁⁽¹⁾ ~ Gamma({alpha_1}, {beta_1})\")\n",
    "\n",
    "# Sample (using mean for demonstration)\n",
    "lambda1_1 = alpha_1 / beta_1\n",
    "print(f\"Sample λ₁⁽¹⁾ = {lambda1_1:.2f} (using mean for demo)\")\n",
    "\n",
    "# Step 2: Sample λ₂\n",
    "print(\"\\nStep 2: Sample λ₂ | x, c, λ₁\")\n",
    "sum_after = np.sum(data[c0:])\n",
    "alpha_2 = alpha + sum_after\n",
    "beta_2 = beta + (N - c0)\n",
    "\n",
    "print(f\"Sum of data after c = {c0}: {sum_after}\")\n",
    "print(f\"α' = {alpha} + {sum_after} = {alpha_2}\")\n",
    "print(f\"β' = {beta} + ({N} - {c0}) = {beta_2}\")\n",
    "print(f\"λ₂⁽¹⁾ ~ Gamma({alpha_2}, {beta_2})\")\n",
    "\n",
    "# Sample (using mean for demonstration)\n",
    "lambda2_1 = alpha_2 / beta_2\n",
    "print(f\"Sample λ₂⁽¹⁾ = {lambda2_1:.2f} (using mean for demo)\")\n",
    "\n",
    "# Step 3: Sample c\n",
    "print(\"\\nStep 3: Sample c | x, λ₁, λ₂\")\n",
    "print(f\"Using λ₁ = {lambda1_1:.2f}, λ₂ = {lambda2_1:.2f}\")\n",
    "\n",
    "log_probs = []\n",
    "for k in range(1, N):\n",
    "    sum_before_k = np.sum(data[:k])\n",
    "    sum_after_k = np.sum(data[k:])\n",
    "    log_p = (sum_before_k * np.log(lambda1_1) - k * lambda1_1 +\n",
    "             sum_after_k * np.log(lambda2_1) - (N - k) * lambda2_1)\n",
    "    log_probs.append(log_p)\n",
    "    print(f\"\\nc = {k}:\")\n",
    "    print(f\"  Sum before: {sum_before_k}, Sum after: {sum_after_k}\")\n",
    "    print(f\"  log p ∝ {sum_before_k}×log({lambda1_1:.2f}) - {k}×{lambda1_1:.2f} + \"\n",
    "          f\"{sum_after_k}×log({lambda2_1:.2f}) - {N-k}×{lambda2_1:.2f}\")\n",
    "    print(f\"  log p = {log_p:.3f}\")\n",
    "\n",
    "# Normalize probabilities\n",
    "log_probs = np.array(log_probs)\n",
    "log_probs_shifted = log_probs - np.max(log_probs)\n",
    "probs = np.exp(log_probs_shifted)\n",
    "probs = probs / np.sum(probs)\n",
    "\n",
    "print(f\"\\nNormalized probabilities:\")\n",
    "for k, p in enumerate(probs, 1):\n",
    "    print(f\"P(c = {k}) = {p:.3f}\")\n",
    "\n",
    "most_likely_c = np.argmax(probs) + 1\n",
    "print(f\"\\nMost likely: c⁽¹⁾ = {most_likely_c}\")\n",
    "\n",
    "# 2.3 Posterior Predictive\n",
    "print(\"\\n\\n2.3 Posterior Predictive Distribution\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Simulate posterior samples (small example)\n",
    "n_samples = 5\n",
    "samples = {\n",
    "    'c': [3, 3, 4, 3, 2],\n",
    "    'lambda1': [1.9, 2.1, 1.8, 2.0, 2.2],\n",
    "    'lambda2': [5.8, 6.2, 5.5, 6.0, 5.9]\n",
    "}\n",
    "\n",
    "print(\"Posterior samples (example):\")\n",
    "for i in range(n_samples):\n",
    "    print(f\"Sample {i+1}: c={samples['c'][i]}, \"\n",
    "          f\"λ₁={samples['lambda1'][i]:.1f}, λ₂={samples['lambda2'][i]:.1f}\")\n",
    "\n",
    "# Predict for year 7\n",
    "print(\"\\nPredicting accidents for year 7:\")\n",
    "predictions = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    c_i = samples['c'][i]\n",
    "    lambda1_i = samples['lambda1'][i]\n",
    "    lambda2_i = samples['lambda2'][i]\n",
    "    \n",
    "    if 7 <= c_i:\n",
    "        # Before change point\n",
    "        lambda_7 = lambda1_i\n",
    "        pred = np.random.poisson(lambda_7)\n",
    "    else:\n",
    "        # After change point\n",
    "        lambda_7 = lambda2_i\n",
    "        pred = np.random.poisson(lambda_7)\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    print(f\"Sample {i+1}: c={c_i}, 7>c: {7>c_i}, \"\n",
    "          f\"λ={lambda_7:.1f}, x₇={pred}\")\n",
    "\n",
    "print(f\"\\nPosterior predictive mean: E[x₇|x] = {np.mean(predictions):.1f}\")\n",
    "\n",
    "# 2.4 Decision Making\n",
    "print(\"\\n\\n2.4 Decision Making\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Check if accident rate decreased\n",
    "print(\"Question: Has the accident rate decreased?\")\n",
    "print(\"Compute: P(λ₁ > λ₂ | x)\")\n",
    "\n",
    "count_decreased = sum(1 for i in range(n_samples) \n",
    "                     if samples['lambda1'][i] > samples['lambda2'][i])\n",
    "prob_decreased = count_decreased / n_samples\n",
    "\n",
    "print(f\"\\nSamples where λ₁ > λ₂: {count_decreased}/{n_samples}\")\n",
    "print(f\"P(λ₁ > λ₂ | x) = {prob_decreased:.2f}\")\n",
    "\n",
    "if prob_decreased < 0.5:\n",
    "    print(f\"\\nConclusion: Strong evidence that accident rate INCREASED\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: Evidence that accident rate DECREASED\")\n",
    "\n",
    "# =============================================================================\n",
    "# PART 3: SUMMARY AND VISUALIZATION\n",
    "# =============================================================================\n",
    "print(\"\\n\\nPART 3: SUMMARY AND VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Visualize bimodal distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Bimodal distribution\n",
    "ax = axes[0, 0]\n",
    "x_range = np.linspace(-8, 6, 1000)\n",
    "y_bimodal = p_bimodal(x_range)\n",
    "ax.plot(x_range, y_bimodal, 'b-', linewidth=2)\n",
    "ax.axvline(-3, color='r', linestyle='--', alpha=0.5, label='Mode 1')\n",
    "ax.axvline(1, color='g', linestyle='--', alpha=0.5, label='Mode 2')\n",
    "ax.axvline(-1, color='k', linestyle='--', alpha=0.5, label='True mean')\n",
    "ax.set_title('Bimodal Distribution')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('p(x)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Chain traces\n",
    "ax = axes[0, 1]\n",
    "ax.plot(chain1, 'b-', label='Chain 1', marker='o')\n",
    "ax.plot(chain2, 'r-', label='Chain 2', marker='o')\n",
    "ax.set_title(f'Chain Traces (R̂={R_hat:.2f})')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Sample value')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Change point data\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(range(1, N+1), data, s=100, alpha=0.7)\n",
    "ax.axvline(c0 + 0.5, color='r', linestyle='--', label=f'Initial c={c0}')\n",
    "ax.set_title('Change Point Data')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Accident count')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Posterior for c\n",
    "ax = axes[1, 1]\n",
    "c_values = range(1, N)\n",
    "ax.bar(c_values, probs, alpha=0.7, color='blue')\n",
    "ax.set_title('Posterior P(c|x) - One iteration')\n",
    "ax.set_xlabel('Change point c')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# SUMMARY\n",
    "# =============================================================================\n",
    "print(\"\\n\\n=== SUMMARY ===\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. BIMODAL DISTRIBUTION:\")\n",
    "print(\"   - Purpose: Test MCMC convergence on challenging distribution\")\n",
    "print(\"   - Problem: Multiple modes can trap chains\")\n",
    "print(\"   - Diagnostic: R̂ compares within/between chain variance\")\n",
    "print(f\"   - Result: R̂ = {R_hat:.2f} indicates {('poor' if R_hat > 1.1 else 'good')} convergence\")\n",
    "\n",
    "print(\"\\n2. CHANGE POINT DETECTION:\")\n",
    "print(\"   - Purpose: Find when accident rates changed\")\n",
    "print(\"   - Problem: Unknown change point and rates\")\n",
    "print(\"   - Method: Gibbs sampling (conditional distributions)\")\n",
    "print(\"   - Result: Can identify change point and quantify uncertainty\")\n",
    "\n",
    "print(\"\\n3. KEY INSIGHTS:\")\n",
    "print(\"   - Multiple chains essential for convergence diagnosis\")\n",
    "print(\"   - R̂ near 1 indicates good mixing\")\n",
    "print(\"   - ESS accounts for autocorrelation\")\n",
    "print(\"   - Gibbs sampling efficient for conditional conjugacy\")\n",
    "print(\"   - Posterior predictive checks model fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19bad0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
