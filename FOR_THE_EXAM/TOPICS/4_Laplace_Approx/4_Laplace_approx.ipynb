{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b402de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper functions\n",
    "sigmoid = lambda x: 1./(1 + jnp.exp(-x))\n",
    "\n",
    "class LogisticRegression(object):\n",
    "    \"\"\"\n",
    "    Bayesian Logistic Regression with MAP estimation.\n",
    "    \n",
    "    Model:\n",
    "    - Prior: w ~ N(0, α⁻¹I)\n",
    "    - Likelihood: y_n | w, x_n ~ Bernoulli(σ(w^T x_n))\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, feature_transformation=lambda x: x, alpha=1.):\n",
    "        # Store data and hyperparameters\n",
    "        self.X0 = X\n",
    "        self.y = y\n",
    "        self.alpha = alpha\n",
    "        self.feature_transformation = feature_transformation\n",
    "        \n",
    "        # Transform and standardize features\n",
    "        self.X = feature_transformation(self.X0)\n",
    "        self.X_mean = jnp.mean(self.X, 0)\n",
    "        self.X_std = jnp.std(self.X, 0)\n",
    "        self.X_std = jnp.where(self.X_std == 0, 1, self.X_std)\n",
    "        self.X = self.preprocess(X)\n",
    "        \n",
    "        self.N, self.D = self.X.shape\n",
    "        \n",
    "        # Find MAP estimate\n",
    "        self.w_MAP = self.get_MAP()\n",
    "    \n",
    "    def preprocess(self, X_):\n",
    "        \"\"\"Standardize features\"\"\"\n",
    "        X = self.feature_transformation(X_)\n",
    "        return (X - self.X_mean) / self.X_std\n",
    "    \n",
    "    def predict(self, X, w):\n",
    "        \"\"\"Compute p(y=1|X, w) = σ(Xw)\"\"\"\n",
    "        return sigmoid(X @ w)\n",
    "    \n",
    "    def log_joint(self, w):\n",
    "        \"\"\"\n",
    "        Log joint probability: log p(y, w)\n",
    "        = log p(w) + Σ_n log p(y_n | x_n, w)\n",
    "        \"\"\"\n",
    "        # Log prior: -½ α w^T w\n",
    "        log_prior = -0.5 * self.alpha * jnp.sum(w**2)\n",
    "        \n",
    "        # Log likelihood: Σ_n [y_n log σ(f_n) + (1-y_n) log(1-σ(f_n))]\n",
    "        p = self.predict(self.X, w)\n",
    "        log_lik = jnp.sum(self.y * jnp.log(p) + (1 - self.y) * jnp.log(1 - p))\n",
    "        \n",
    "        return log_prior + log_lik\n",
    "    \n",
    "    def grad(self, w):\n",
    "        \"\"\"\n",
    "        Gradient of log joint:\n",
    "        ∇log p(y,w) = -Σ_n (p_n - y_n) x_n - α w\n",
    "        \"\"\"\n",
    "        p = self.predict(self.X, w)\n",
    "        err = p - self.y\n",
    "        return -self.X.T @ err - self.alpha * w\n",
    "    \n",
    "    def hessian(self, w):\n",
    "        \"\"\"\n",
    "        Hessian of log joint:\n",
    "        H = -X^T diag(p(1-p)) X - αI\n",
    "        \"\"\"\n",
    "        p = self.predict(self.X, w)\n",
    "        v = p * (1 - p)\n",
    "        return -self.X.T @ jnp.diag(v) @ self.X - self.alpha * jnp.eye(self.D)\n",
    "    \n",
    "    def get_MAP(self):\n",
    "        \"\"\"Find MAP estimate by optimization\"\"\"\n",
    "        init_w = jnp.zeros(self.D)\n",
    "        results = minimize(\n",
    "            lambda w: -self.log_joint(w),\n",
    "            jac=lambda w: -self.grad(w),\n",
    "            x0=init_w\n",
    "        )\n",
    "        if not results.success:\n",
    "            raise ValueError('Optimization failed')\n",
    "        return results.x\n",
    "\n",
    "class LaplaceApproximation(object):\n",
    "    \"\"\"\n",
    "    Laplace approximation for posterior p(w|y) ≈ N(w|m, S)\n",
    "    where m = w_MAP and S = -H⁻¹\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "        # Posterior mean = MAP\n",
    "        self.posterior_mean = model.w_MAP\n",
    "        \n",
    "        # Hessian at MAP\n",
    "        self.posterior_hessian = model.hessian(model.w_MAP[None, :])[0]\n",
    "        \n",
    "        # Posterior covariance = -H⁻¹\n",
    "        self.posterior_cov = -jnp.linalg.inv(self.posterior_hessian)\n",
    "    \n",
    "    def log_pdf(self, w):\n",
    "        \"\"\"Log density of approximate posterior\"\"\"\n",
    "        return mvn.logpdf(w, self.posterior_mean, self.posterior_cov)\n",
    "    \n",
    "    def sample(self, key, num_samples):\n",
    "        \"\"\"Sample from approximate posterior\"\"\"\n",
    "        return mvn.rvs(self.posterior_mean, self.posterior_cov, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16393f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27fecc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02477_Bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
